# StyleGAN-Keras
Keras implementation of StyleGAN based on NVIDIAâ€™s paper. Supports style-based image generation (4Ã—4 to 256Ã—256) with AdaIN. Includes SPADE normalization for semantic synthesis. Mixing regularity included; progressive growth not yet implemented. Open for contributions.

StyleGAN-Keras

A Keras implementation of StyleGAN, based on the research paper

A Style-Based Generator Architecture for Generative Adversarial Networks
by Tero Karras et al., NVIDIA (2018).

This repository also includes an implementation of Spatially-Adaptive Normalization (SPADE) adapted from:

Semantic Image Synthesis with Spatially-Adaptive Normalization
by Taesung Park et al., NVIDIA (2019).

â¸»

ðŸ”¬ Project Highlights
	â€¢	Style-Based Generator Architecture with control over coarse-to-fine style levels.
	â€¢	Implements AdaIN (Adaptive Instance Normalization) and includes SPADE code (AdaIN.py).
	â€¢	Provides different configurations:
	â€¢	stylegan.py â†’ Basic StyleGAN generator/discriminator.
	â€¢	mixing-stylegan.py â†’ Incorporates style mixing regularities.
	â€¢	Growth/Progressive training is not implemented yet â€” Contributions are welcome!

â¸»

ðŸ§± Architecture
	â€¢	Input (Z-space): Latent vector mapped via an MLP to intermediate latent space (W).
	â€¢	Style Blocks: Influence generator at different resolutions using AdaIN.
	â€¢	Resolution: Configurable from 4Ã—4 up to 32Ã—32 in rows and 256Ã—256 in columns.
	â€¢	Noise Injection: Per-layer noise is added to encourage stochastic variation.

â¸»

ðŸ§ª SPADE Integration

Code for SPADE (Spatially-Adaptive Denormalization) is available in AdaIN.py, offering a foundation for experimentation with conditional image generation based on segmentation maps or other spatial data.
